diff -Naur linux-2.6.8/drivers/md/dm-bde/dm_bde_crypt.c linux-2.6.8-dmbde/drivers/md/dm-bde/dm_bde_crypt.c
--- linux-2.6.8/drivers/md/dm-bde/dm_bde_crypt.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.8-dmbde/drivers/md/dm-bde/dm_bde_crypt.c	2005-11-20 13:45:39.594703544 +0100
@@ -0,0 +1,506 @@
+/* Hey Emacs, take a hint: -*- linux-c -*-
+ *
+ * dm_bde_crypt.c is a part of the Linux port of GBDE from FreeBSD, written by 
+ * Poul-Henning Kamp (PHK). Permission has been given by PHK to release 
+ * this software under GPL, as long as the original BSD licence is included
+ * in the source.
+ *
+ * dm_bde_crypt.c is 
+ * Copyright (c) 2004-2005 Thomas S. Iversen and
+ * Copyright (c) 2002 Poul-Henning Kamp
+ * Copyright (c) 2002 Networks Associates Technology, Inc.
+ * All rights reserved.
+ *        
+ *
+ *                     - GPL Licence -
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.		    
+ *
+ *
+ *                     - BSD Licence -
+ *
+ *
+ * This software was developed for the FreeBSD Project by Poul-Henning Kamp
+ * and NAI Labs, the Security Research Division of Network Associates, Inc.
+ * under DARPA/SPAWAR contract N66001-01-C-8035 ("CBOSS"), as part of the
+ * DARPA CHATS research program.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * $FreeBSD: src/sys/geom/bde/g_bde_crypt.c,v 1.18 2003/09/08 18:35:26 phk Exp $
+ *
+ * This source file contains the functions responsible for the crypto, keying
+ * and mapping operations on the I/O requests.
+ *
+ */
+#
+#include <linux/crypto.h>
+#include <linux/random.h>
+#include <asm/div64.h>
+
+#include "../dm.h"
+#include "dm_bde.h"
+
+unsigned int normalize(unsigned long long x) {
+	unsigned int n;
+	
+	if (x == 0) return(64);
+	n = 0;
+	if (x <= 0x00000000FFFFFFFFULL) {n = n + 32; x = x << 32;}
+	if (x <= 0x0000FFFFFFFFFFFFULL) {n = n + 16; x = x << 16;}
+	if (x <= 0x00FFFFFFFFFFFFFFULL) {n = n +  8; x = x <<  8;}
+	if (x <= 0x0FFFFFFFFFFFFFFFULL) {n = n +  4; x = x <<  4;}
+	if (x <= 0x3FFFFFFFFFFFFFFFULL) {n = n +  2; x = x <<  2;}
+	if (x <= 0x7FFFFFFFFFFFFFFFULL) {n = n +  1;}
+	return n;
+}
+
+
+unsigned long long udivi64_64(uint64_t *u,
+			      unsigned long long *v) {
+	
+	unsigned long v32;
+	unsigned long v1;
+	unsigned long q0, q1;
+	
+	uint64_t u1;
+	unsigned int n;
+	
+	if (*v >> 32 == 0) {                               
+		/* if v < 2^32, use do_div macro */
+
+		v32 = (unsigned long) (*v & 0xFFFFFFFFULL);
+		return do_div(*u, v32) & 0xFFFFFFFFULL;
+	}
+
+	/* if v >= 2^32, normalize divisor:
+	 *
+	 * Normalize the divisor v to fit in a 32 bit v1, so its MSB==1
+	 * Divide u with the divisor v1, but take care of overflow by
+	 * shift u 1 to the right first, ensuring no overflow is possible.
+	 *
+	 * use do_div to do a 64/32 divide. 
+	 *
+	 * Undo normalization and return values.
+	 *
+	 */
+	
+	n = normalize(*v);         
+	v1 = (*v << n) >> 32;
+	                          
+	u1 = *u >> 1;
+	q1 = do_div(u1, v1) & 0xFFFFFFFFULL;
+		                        
+	q0 = (q1 << n) >> 31;
+	                                
+	if (q0 != 0)
+		q0 = q0 - 1;
+	if ((*u - q0* *v) >= *v)
+		q0 = q0 + 1;
+	*u = u1;
+	return q0;
+}
+
+
+/*
+ * Derive kkey from mkey + sector offset.
+ *
+ * Security objective: Derive a potentially very large number of distinct skeys
+ * from the comparatively small key material in our mkey, in such a way that
+ * if one, more or even many of the kkeys are compromised, this does not
+ * significantly help an attack on other kkeys and in particular does not
+ * weaken or compromised the mkey.
+ *
+ * First we MD5 hash the sectornumber with the salt from the lock sector.
+ * The salt prevents the precalculation and statistical analysis of the MD5
+ * output which would be possible if we only gave it the sectornumber.
+ *
+ * The MD5 hash is used to pick out 16 bytes from the masterkey, which
+ * are then hashed with MD5 together with the sector number.
+ *
+ * The resulting MD5 hash is the kkey.
+ */
+
+static void
+dm_bde_kkey(struct dm_bde_softc *sc, struct crypto_tfm *aes_tfm, uint64_t offset)
+{
+	u_int t;
+        struct crypto_tfm *md5_tfm;
+        struct scatterlist sg[2];
+	u_char buf[16];
+	u_char buf2[8];
+	u64 *ptr=(u64 *)&buf2;
+	
+
+	md5_tfm = crypto_alloc_tfm("md5", 0);
+	if (md5_tfm == NULL)
+		return;
+
+	/* We have to be architecture neutral */
+	*ptr = cpu_to_le64(offset);
+
+	crypto_digest_init (md5_tfm);
+
+	sg[0].page = virt_to_page (sc->key.salt);
+	sg[0].offset = offset_in_page (sc->key.salt);
+	sg[0].length = 8;
+	crypto_digest_update (md5_tfm, sg, 1);
+
+	sg[0].page = virt_to_page (&buf2);
+	sg[0].offset = offset_in_page (&buf2);
+	sg[0].length = sizeof buf2;
+	crypto_digest_update (md5_tfm, sg, 1);
+
+	sg[0].page = virt_to_page (sc->key.salt + 8);
+	sg[0].offset = offset_in_page (sc->key.salt + 8);
+	sg[0].length = 8;
+	crypto_digest_update (md5_tfm, sg, 1);
+
+	crypto_digest_final (md5_tfm, buf);
+
+	crypto_digest_init (md5_tfm);
+
+	sg[1].page = virt_to_page (&buf2);
+	sg[1].offset = offset_in_page (&buf2);
+	sg[1].length = sizeof buf2;
+
+	for (t = 0; t < 16; t++) {
+		sg[0].page = virt_to_page (&sc->key.mkey[buf[t]]);
+		sg[0].offset = offset_in_page (&sc->key.mkey[buf[t]]);
+		sg[0].length = 1;
+		crypto_digest_update (md5_tfm, sg, 1);
+
+		if (t == 8)
+			crypto_digest_update (md5_tfm, &sg[1], 1);
+	}
+	memset(buf2, 0, sizeof buf2);
+	crypto_digest_final (md5_tfm, buf);
+	crypto_free_tfm(md5_tfm);
+
+	crypto_cipher_setkey(aes_tfm, buf, DM_BDE_SKEYLEN);
+
+	memset(buf, 0, sizeof buf);
+	return;
+
+}
+
+/*
+ * Encryption work for read operation.
+ *
+ * Security objective: Find the kkey, find the skey, decrypt the sector data.
+ */
+
+void
+dm_bde_crypt_read(struct dm_bde_work *wp)
+{
+	struct dm_bde_softc *sc;
+	struct crypto_tfm *aes_tfm;
+	struct scatterlist sg[2];
+
+	unsigned int iv_size;
+	u8 *iv;
+
+	u_char *d;
+	unsigned int wpdata;
+	u_int n;
+	u_int i;
+	off_t o;
+	u_char skey[DM_BDE_SKEYLEN];
+
+	aes_tfm=crypto_alloc_tfm("aes", CRYPTO_TFM_MODE_CBC);
+	if (!aes_tfm)
+		return;
+       
+	iv_size=crypto_tfm_alg_ivsize (aes_tfm);
+	iv= (u8 *)kmalloc(iv_size, GFP_KERNEL);
+	if(!iv) {
+		crypto_free_tfm(aes_tfm);
+		return;
+	}
+
+	memset(iv,0,iv_size);
+ 
+	sc = wp->softc;
+
+	o = 0;
+	n = 0;
+
+	for (i = 0; i < wp->bi_vcnt; i++) {
+		for(wpdata = wp->bi_io_vec[i].bv_offset ; wpdata < wp->bi_io_vec[i].bv_offset+wp->bi_io_vec[i].bv_len ; wpdata += sc->sectorsize) {
+			d = (u_char *)wp->ksp->sectordata + wp->ko + n * DM_BDE_SKEYLEN;
+			
+			dm_bde_kkey(sc, aes_tfm, wp->offset + o);
+			
+			sg[0].page = virt_to_page(d);
+			sg[0].offset = offset_in_page(d);
+			sg[0].length = DM_BDE_SKEYLEN;
+			
+
+			sg[1].page = virt_to_page(&skey);
+			sg[1].offset = offset_in_page(&skey);
+			sg[1].length = DM_BDE_SKEYLEN;
+			
+			crypto_cipher_set_iv(aes_tfm, iv, iv_size);
+			crypto_cipher_decrypt(aes_tfm, &sg[1], &sg[0], DM_BDE_SKEYLEN);
+			
+			crypto_cipher_setkey(aes_tfm, skey, DM_BDE_SKEYLEN);
+			
+			sg[0].page = wp->bi_io_vec[i].bv_page;
+			sg[0].offset = wpdata;
+			sg[0].length = sc->sectorsize;
+			
+			crypto_cipher_set_iv(aes_tfm, iv, iv_size);
+			crypto_cipher_decrypt(aes_tfm, &sg[0], &sg[0], sc->sectorsize);
+
+			n++;
+			o += sc->sectorsize;
+		}
+	}
+
+	kfree(iv);
+	crypto_free_tfm(aes_tfm);
+	memset(skey, 0, sizeof skey);
+}
+
+/*
+ * Encryption work for write operation.
+ *
+ * Security objective: Create random skey, encrypt sector data,
+ * encrypt skey with the kkey.
+ */
+
+void
+dm_bde_crypt_write(struct dm_bde_work *wp)
+{
+	u_char *d;
+	struct dm_bde_softc *sc;
+	struct crypto_tfm *aes_tfm;
+	struct scatterlist sg[2];
+
+	unsigned int iv_size;
+	u8 *iv;
+
+	int ret;
+	unsigned int wpdata;
+	u_int i;
+	u_int n;
+	off_t o;
+	u_char skey[DM_BDE_SKEYLEN];
+
+	
+	sc = wp->softc;
+
+	aes_tfm=crypto_alloc_tfm("aes", CRYPTO_TFM_MODE_CBC);
+	if (!aes_tfm)
+		return;
+
+	iv_size=crypto_tfm_alg_ivsize (aes_tfm);
+	iv= (u8 *)kmalloc(iv_size, GFP_KERNEL);
+	if(!iv) {
+		crypto_free_tfm(aes_tfm);
+		return;
+	}
+
+	memset(iv,0,iv_size);
+
+	n = 0;
+	o = 0;
+	for (i = 0; i < wp->bi_vcnt; i++) {
+		for(wpdata = wp->bi_io_vec[i].bv_offset ; wpdata < wp->bi_io_vec[i].bv_offset+wp->bi_io_vec[i].bv_len ; wpdata += sc->sectorsize) {
+
+			get_random_bytes(&skey, sizeof skey);
+			ret = crypto_cipher_setkey(aes_tfm, skey, DM_BDE_SKEYLEN);
+			
+			sg[0].page = wp->bi_io_vec[i].bv_page;
+			sg[0].offset = wpdata;
+			sg[0].length = sc->sectorsize;
+			
+			
+			sg[1].page = wp->sp->bi_io_vec[i].bv_page;
+			sg[1].offset = wpdata;
+			sg[1].length = sc->sectorsize;
+			
+			crypto_cipher_set_iv(aes_tfm, iv, iv_size);
+			crypto_cipher_encrypt(aes_tfm, &sg[1], &sg[0], sc->sectorsize);
+			
+			d = (u_char *)wp->ksp->sectordata + wp->ko + n * DM_BDE_SKEYLEN;
+			dm_bde_kkey(sc, aes_tfm, wp->offset + o);
+			
+			sg[0].page = virt_to_page(skey);
+			sg[0].offset = offset_in_page(skey);
+			sg[0].length = sizeof skey;
+			
+			sg[1].page = virt_to_page(d);
+			sg[1].offset = offset_in_page(d);
+			sg[1].length = sizeof skey;
+			
+			crypto_cipher_set_iv(aes_tfm, iv, iv_size);
+			crypto_cipher_encrypt(aes_tfm, &sg[1], &sg[0], sizeof skey);
+			
+			n++;
+			o += sc->sectorsize;
+		}		  
+		
+	}
+	memset(skey, 0, sizeof skey);
+	kfree(iv);
+	crypto_free_tfm(aes_tfm);
+}
+
+
+
+/*
+ * Calculate the total payload size of the encrypted device.
+ *
+ * Security objectives: none.
+ *
+ * This function needs to agree with dm_bde_map_sector() about things.
+ */
+
+
+uint64_t
+dm_bde_max_sector(struct dm_bde_key *kp)
+{
+	uint64_t maxsect;
+
+	maxsect = kp->media_width;
+
+	(void *) do_div(maxsect, kp->zone_width);
+
+	maxsect *= kp->zone_cont;
+	return (maxsect);
+}
+
+/*
+ * Convert an unencrypted side offset to offsets on the encrypted side.
+ *
+ * Security objective:  Make it harder to identify what sectors contain what
+ * on a "cold" disk image.
+ *
+ * We do this by adding the "keyoffset" from the lock to the physical sector
+ * number modulus the available number of sectors.  Since all physical sectors
+ * presumably look the same cold, this will do.
+ *
+ * As part of the mapping we have to skip the lock sectors which we know
+ * the physical address off.  We also truncate the work packet, respecting
+ * zone boundaries and lock sectors, so that we end up with a sequence of
+ * sectors which are physically contiguous.
+ *
+ * Shuffling things further is an option, but the incremental frustration is
+ * not currently deemed worth the run-time performance hit resulting from the
+ * increased number of disk arm movements it would incur.
+ *
+ * This function offers nothing but a trivial diversion for an attacker able
+ * to do "the cleaning lady attack" in its current static mapping form.
+ */
+
+void
+dm_bde_map_sector(struct dm_bde_work *wp)
+{
+	u_int	zone, zoff, u, len;
+	uint64_t ko;
+	uint64_t tmp;
+	uint32_t tmp1;
+	uint64_t tmp2;
+	struct dm_bde_softc *sc;
+	struct dm_bde_key *kp;
+
+	sc = wp->softc;
+	kp = &sc->key;
+
+	/* find which zone and the offset in it */
+	tmp  = wp->offset;
+	zoff = do_div(tmp, kp->zone_cont);
+	zone = tmp;
+
+	/* Calculate the offset of the key in the key sector */
+	wp->ko = (zoff / kp->sectorsize) * DM_BDE_SKEYLEN;
+
+	/* restrict length to that zone */
+	len = kp->zone_cont - zoff;
+
+	/* ... and in general */
+//FIXME	if (len > DFLTPHYS)
+//		len = DFLTPHYS;
+
+	if (len < wp->length)
+		wp->length = len;
+
+	/* Find physical sector address */
+	wp->so = zone * kp->zone_width + zoff;
+
+	wp->so += kp->keyoffset;
+
+	tmp2 = (unsigned long long)wp->so;
+	tmp1 = udivi64_64(&tmp2, &kp->media_width);
+	wp->so = tmp1;
+
+	if (wp->so + wp->length > kp->media_width)
+	        wp->length = kp->media_width - wp->so;
+
+	wp->so += kp->sector0;
+
+	/* The key sector is the last in this zone. */
+	wp->kso = zone * kp->zone_width + kp->zone_cont;
+
+	wp->kso += kp->keyoffset;
+
+//FIXME	wp->kso %= kp->media_width;
+
+	tmp2 = (unsigned long long)wp->kso;
+	tmp = udivi64_64(&tmp2, &kp->media_width);
+	wp->kso = tmp;
+
+	wp->kso += kp->sector0; 
+
+	/* Compensate for lock sectors */
+	for (u = 0; u < DM_BDE_MAXKEYS; u++) {
+		/* Find the start of this lock sector */
+		ko = kp->lsector[u] & ~(kp->sectorsize - 1);
+		if (wp->kso >= ko)
+			wp->kso += kp->sectorsize;
+
+		if (wp->so >= ko) {
+			/* lock sector before work packet */
+			wp->so += kp->sectorsize;
+
+		} else if ((wp->so + wp->length) > ko) {
+			/* lock sector in work packet, truncate */
+			wp->length = ko - wp->so;
+		}
+	}
+
+	ddprintk(BDE "off %lld len %lld so %lld kso %lld ko %u\n",(unsigned long long)wp->offset, (unsigned long long)wp->length, (unsigned long long)wp->so, (unsigned long long)wp->kso, wp->ko);
+}
+
diff -Naur linux-2.6.8/drivers/md/dm-bde/dm_bde.h linux-2.6.8-dmbde/drivers/md/dm-bde/dm_bde.h
--- linux-2.6.8/drivers/md/dm-bde/dm_bde.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.8-dmbde/drivers/md/dm-bde/dm_bde.h	2005-11-20 13:47:24.659731232 +0100
@@ -0,0 +1,215 @@
+/* Hey Emacs, take a hint: -*- linux-c -*- */
+
+#ifndef _DM_BDE_H_
+#define _DM_BDE_H_ 1
+
+/* DEBUG
+ *   Define it if you want verbose debug output, e.g. for bug reporting
+ */
+//#define DMBDE_DEBUG
+
+#ifdef DMBDE_DEBUG
+#define ddprintk(msg...) printk(msg)
+#else
+#define ddprintk(msg...) do { } while(0)
+#endif
+
+
+/*
+ * These are quite, but not entirely unlike constants.
+ *
+ * They are not commented in details here, to prevent unadvisable
+ * experimentation. Please consult the code where they are used before you
+ * even think about modifying these.
+ */
+
+/* Number of ms to sleep if we have nothing to do */
+#define DM_BDE_SLEEP_LENGTH HZ
+
+#define DM_BDE_MKEYLEN	(2048/8)
+#define DM_BDE_SKEYBITS	128
+#define DM_BDE_SKEYLEN	(DM_BDE_SKEYBITS/8)
+#define DM_BDE_KKEYBITS	128
+#define DM_BDE_KKEYLEN	(DM_BDE_KKEYBITS/8)
+#define DM_BDE_MAXKEYS	4
+#define DM_BDE_LOCKSIZE	384
+#define NLOCK_FIELDS	13
+#define SHA512_DIGEST_LENGTH 64
+
+#define BDE	"dm_bde: "
+#define MIN_IOS        128
+#define MIN_KEYSECTORS 128
+#define MIN_SECTORS    128
+#define MIN_WPS       128
+#define MIN_POOL_PAGES 128
+#define MIN_SECTOR_STRUCTS 128
+
+
+#define KASSERT(exp,msg) do {if(!unlikely(exp)) BUG();} while(0)
+
+struct dm_bde_io {
+	struct dm_target *target;
+	atomic_t completed;
+};
+
+/* This just needs to be "large enough" */
+#define DM_BDE_KEYBYTES	304
+
+struct dm_bde_work;
+struct dm_bde_softc;
+
+struct dm_bde_sector {
+	struct dm_bde_work	*owner;
+	struct dm_bde_softc	*softc;
+	struct completion complete_io;
+	uint64_t		offset;
+	u_int			size;
+	u_int			ref;
+
+	unsigned long           *sectordata;
+	int                     bi_vcnt;
+        struct bio_vec          *bi_io_vec;
+
+
+	struct list_head        list;
+	u_char			valid;
+	u_char			malloc;
+	enum {JUNK, IO, VALID}	state;
+	int			error;
+	unsigned long		used;
+
+	struct bio              *bp;
+	struct work_struct      wsp;
+	int                     bytes_done;
+};
+
+struct dm_bde_work {
+	uint64_t		offset;
+	off_t                   length;
+	struct bio      	*bp;
+	struct dm_bde_softc 	*softc;
+	struct completion       event;
+	uint64_t           	so;
+        uint64_t           	kso;
+        u_int           	ko;
+        struct dm_bde_sector   	*sp;
+        struct dm_bde_sector   	*ksp;
+	struct list_head        list;
+
+	enum {SETUP, WAIT, FINISH} state;
+	int			error;
+	int                     bi_vcnt;
+        struct bio_vec          *bi_io_vec;
+	struct dm_target        *target;
+	struct dm_bde_io *io;
+};
+
+/*
+ * The decrypted contents of the lock sectors.  Notice that this is not
+ * the same as the on-disk layout.  The on-disk layout is dynamic and
+ * dependent on the pass-phrase.
+ */
+struct dm_bde_key {
+	uint64_t		sector0;        
+				/* Physical byte offset of 1st byte used */
+	uint64_t		sectorN;
+				/* Physical byte offset of 1st byte not used */
+	uint64_t		keyoffset;
+				/* Number of bytes the disk image is skewed. */
+	uint64_t		lsector[DM_BDE_MAXKEYS];
+				/* Physical byte offsets of lock sectors */
+	uint32_t		sectorsize;
+				/* Our "logical" sector size */
+	uint32_t		flags;
+#define	GBDE_F_SECT0		1
+	uint8_t			salt[16];
+				/* Used to frustate the kkey generation */
+	uint8_t			spare[32];
+				/* For future use, random contents */
+	uint8_t			mkey[DM_BDE_MKEYLEN];
+				/* Our masterkey. */
+
+	/* Non-stored help-fields */
+	uint64_t		zone_width;	/* On-disk width of zone */
+	uint64_t		zone_cont;	/* Payload width of zone */
+	uint64_t		media_width;	/* Non-magic width of zone */
+	u_int			keys_per_sector;
+};
+
+struct dm_bde_softc {
+	struct dm_dev *dev;
+	
+	mempool_t *wp_pool;
+	mempool_t *keysector_pool;
+	mempool_t *sector_pool;
+	mempool_t *struct_sector_pool;
+	mempool_t *io_pool;
+	mempool_t *page_pool;
+	struct work_struct work;
+
+	long number_of_map_calls;
+
+	unsigned long time_spent_encrypting;
+	unsigned long encrypt_bytes;
+  long sleep_accumulated;
+  long decrypts;
+  long ksp_releases;
+  long ksp_newowner_search;
+  long ksp_newowner_found;
+
+  long wp_allocated;
+  long fetched_wp;
+  long wasted_wait;
+  long wasted_io;
+  long wasted_notowner;
+	long no_new_sector;
+
+  long sector_reads;
+  long keysector_reads;
+	int                     busy;
+  int                           work_todo;
+  int worklistscans;
+	uint64_t		mediasize;
+	u_int			sectorsize;
+	uint64_t		zone_cont;
+
+	struct list_head worklist; /* dm_bde_work */
+	struct list_head freelist; /* dm_bde_sector */
+
+	struct semaphore	worklist_mutex;
+	wait_queue_head_t	waitq;
+	struct dm_bde_key	key;
+	int			dead;
+	u_int			nwork;
+	u_int			nsect;
+	u_int			nsectdata;
+	u_int			ncache;
+	u_char			sha2[SHA512_DIGEST_LENGTH];
+};
+
+
+/* dm_bde_lock.c */
+int dm_bde_decode_lock(struct dm_bde_softc *sc, struct dm_bde_key *gl, u_char *ptr);
+int dm_bde_keyloc_decrypt(u_char *sha2, void *input, uint64_t *output);
+int dm_bde_decrypt_lock(struct dm_target *ti, struct dm_bde_softc *sc, u_char *keymat, u_char *meta, uint64_t mediasize, u_int sectorsize, u_int *nkey);
+
+uint64_t dm_bde_max_sector(struct dm_bde_key *lp);
+void dm_bde_map_sector(struct dm_bde_work *wp);
+
+/* dm_bde_work.c */
+void dm_bde_start1(struct dm_target *ti, struct bio *bp, struct dm_bde_io *io);
+int
+dm_bde_start_read(struct dm_bde_work *wp, struct dm_bde_sector *sp);
+void kdmbded_queue_work(struct dm_bde_softc *sc);
+struct dm_bde_work * dm_bde_new_work(struct dm_bde_softc *sc);
+void dm_bde_delete_work(struct dm_bde_work *wp);
+void dm_bde_delete_sector(struct dm_bde_softc *sc, struct dm_bde_sector *sp);
+struct dm_bde_sector * dm_bde_new_sector(struct dm_bde_work *wp, u_int len);
+
+
+void dm_bde_crypt_read(struct dm_bde_work *wp);
+void dm_bde_crypt_write(struct dm_bde_work *wp);
+
+
+
+#endif /* _DM_BDE_H_ */
diff -Naur linux-2.6.8/drivers/md/dm-bde/dm_bde_lock.c linux-2.6.8-dmbde/drivers/md/dm-bde/dm_bde_lock.c
--- linux-2.6.8/drivers/md/dm-bde/dm_bde_lock.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.8-dmbde/drivers/md/dm-bde/dm_bde_lock.c	2005-11-20 13:46:28.770227728 +0100
@@ -0,0 +1,524 @@
+/* Hey Emacs, take a hint: -*- linux-c -*-
+ *
+ * dm_bde_lock.c is a part of the Linux port of GBDE from FreeBSD, written by 
+ * Poul-Henning Kamp (PHK). Permission has been given by PHK to release 
+ * this software under GPL, as long as the original BSD licence is included
+ * in the source.
+ *
+ * dm_bde_lock.c is 
+ * Copyright (c) 2004-2005 Thomas S. Iversen and
+ * Copyright (c) 2002 Poul-Henning Kamp
+ * Copyright (c) 2002 Networks Associates Technology, Inc.
+ * All rights reserved.
+ *        
+ *
+ *                     - GPL Licence -
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.		    
+ *
+ *
+ *                     - BSD Licence -
+ *
+ * This software was developed for the FreeBSD Project by Poul-Henning Kamp
+ * and NAI Labs, the Security Research Division of Network Associates, Inc.
+ * under DARPA/SPAWAR contract N66001-01-C-8035 ("CBOSS"), as part of the
+ * DARPA CHATS research program.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * $FreeBSD: src/sys/geom/bde/g_bde_lock.c,v 1.12 2003/10/07 09:28:07 phk Exp $
+ *
+ * This souce file contains routines which operates on the lock sectors, both
+ * for the kernel and the userland program gbde(1).
+ *
+ */
+
+#include <linux/crypto.h>
+#include <asm/div64.h>
+
+#include "../dm.h"
+#include "dm_bde.h"
+
+static int dm_bio_complete(struct bio *bio, unsigned int bytes_done, int error)
+{
+	if (bio->bi_size)
+		return 1;
+	complete((struct completion*)bio->bi_private);
+	return 0;
+}
+
+
+static int dm_read_data(struct dm_target *ti, uint64_t sector, uint64_t size, char *buf, uint32_t offset, uint32_t len)
+{
+	struct dm_bde_softc *sc = (struct dm_bde_softc *) ti->private;
+	struct bio bio;
+	struct bio_vec vec;
+	struct completion event;
+	struct page *page;
+	struct block_device *bdev;
+
+	page = alloc_page(GFP_NOIO);
+	if (!page)
+		return -ENOMEM;
+
+	bdev = sc->dev->bdev;
+
+	bio_init(&bio);
+	bio.bi_io_vec = &vec;
+	vec.bv_page = page;
+	vec.bv_len = size;
+	vec.bv_offset = 0;
+	bio.bi_vcnt = 1;
+	bio.bi_idx = 0;
+	bio.bi_size = size;
+	bio.bi_bdev = bdev;
+	bio.bi_sector = (sector_t) sector;
+	init_completion(&event);
+	bio.bi_private = &event;
+	bio.bi_end_io = dm_bio_complete;
+	submit_bio(READ, &bio);
+	wait_for_completion(&event);
+
+	memcpy(buf, page_address(vec.bv_page)+offset, len);
+
+	__free_pages(page,0);
+	return 0;
+} 
+
+/*
+ * Encode/Decode the lock structure in byte-sequence format.
+ *
+ * Security objectives: Store in pass-phrase dependent variant format.
+ *
+ * C-structure packing and byte-endianess depends on architecture, compiler
+ * and compiler options.  Writing raw structures to disk is therefore a bad
+ * idea in these enlightend days.
+ *
+ * We spend a fraction of the key-material on shuffling the fields around
+ * so they will be stored in an unpredictable sequence.
+ *
+ * For each byte of the key-material we derive two field indexes, and swap
+ * the position of those two fields.
+ *
+ * I have not worked out the statistical properties of this shuffle, but
+ * given that the key-material has PRN properties, the primary objective
+ * of making it hard to figure out which bits are where in the lock sector
+ * is sufficiently fulfilled.
+ *
+ * We include (and shuffle) an extra hash field in the stored version for
+ * identification and versioning purposes.  This field contains the MD5 hash
+ * of a version identifier (currently "0000") followed by the stored lock
+ * sector byte-sequence substituting zero bytes for the hash field.
+ *
+ * The stored keysequence is protected by AES/256/CBC elsewhere in the code
+ * so the fact that the generated byte sequence has a much higher than
+ * average density of zero bits (from the numeric fields) is not currently
+ * a concern.
+ *
+ * Should this later become a concern, a simple software update and 
+ * pass-phrase change can remedy the situation.  One possible solution 
+ * could be to XOR the numeric fields with a key-material derived PRN.
+ *
+ * The chosen shuffle algorithm only works as long as we have no more than 16 
+ * fields in the stored part of the lock structure (hence the CTASSERT below).
+ */
+
+
+static void
+dm_bde_shuffle_lock(u_char *sha2, int *buf)
+{
+	int j, k, l;
+	u_int u;
+
+	/* Assign the fields sequential positions */
+	for(u = 0; u < NLOCK_FIELDS; u++)
+		buf[u] = u;
+
+	/* Then mix it all up */
+	for(u = 48; u < SHA512_DIGEST_LENGTH; u++) {
+		j = sha2[u] % NLOCK_FIELDS;
+		k = (sha2[u] / NLOCK_FIELDS) % NLOCK_FIELDS;
+		l = buf[j];
+		buf[j] = buf[k];
+		buf[k] = l;
+	}
+}
+
+int
+dm_bde_decode_lock(struct dm_bde_softc *sc, struct dm_bde_key *gl, u_char *ptr)
+{
+	int shuffle[NLOCK_FIELDS];
+	u_char *p;
+	u_char hash[16], hash2[16];
+        struct crypto_tfm *md5_tfm;
+        struct scatterlist sg[2];
+
+	u_char version[4]="0000";
+
+	int i;
+
+	md5_tfm = crypto_alloc_tfm("md5", 0);
+	if (md5_tfm == NULL)
+		return -1;
+
+	p = ptr;
+
+	dm_bde_shuffle_lock(sc->sha2, shuffle);
+
+
+	for (i = 0; i < NLOCK_FIELDS; i++) {
+		switch(shuffle[i]) {
+		case 0:
+			gl->sector0 = le64_to_cpup(p);
+			p += 8;
+			break;
+		case 1:
+			gl->sectorN = le64_to_cpup(p);
+			p += 8;
+			break;
+		case 2:
+			gl->keyoffset = le64_to_cpup(p);
+			p += 8;
+			break;
+		case 3:
+			gl->sectorsize = le32_to_cpup(p);
+			p += 4;
+			break;
+		case 4:
+			gl->flags = le32_to_cpup(p);
+			p += 4;
+			break;
+		case 5:
+		case 6:
+		case 7:
+		case 8:
+			gl->lsector[shuffle[i] - 5] = le64_to_cpup(p);
+			p += 8;
+			break;
+		case 9:
+			memcpy(gl->spare, p, sizeof gl->spare);
+			p += sizeof gl->spare;
+			break;
+		case 10:
+			memcpy(gl->salt, p, sizeof gl->salt);
+			p += sizeof gl->salt;
+			break;
+		case 11:
+			memcpy(gl->mkey, p, sizeof gl->mkey);
+			p += sizeof gl->mkey;
+			break;
+		case 12:
+			memcpy(hash2, p, sizeof hash2);
+			memset(p, 0, sizeof hash2);
+			p += sizeof hash2;
+			break;
+		}
+	}
+
+	if(ptr + DM_BDE_LOCKSIZE != p)
+		goto errout;
+
+	crypto_digest_init (md5_tfm);
+
+	sg[0].page = virt_to_page (version);
+	sg[0].offset = offset_in_page (version);
+	sg[0].length = sizeof version;
+
+	sg[1].page = virt_to_page (ptr);
+	sg[1].offset = offset_in_page (ptr);
+	sg[1].length = DM_BDE_LOCKSIZE;
+
+	memset(hash,0,16);
+	crypto_digest_update (md5_tfm, sg, 2);
+	crypto_digest_final (md5_tfm, hash);
+
+	if (memcmp(hash, hash2, sizeof hash2))
+		goto errout;
+
+	crypto_free_tfm(md5_tfm);
+	return (0);
+
+ errout:
+	crypto_free_tfm(md5_tfm);
+	return -1;
+}
+
+
+
+int
+dm_bde_keyloc_decrypt(u_char *sha2, void *input, uint64_t *output)
+{
+
+	struct crypto_tfm *aes_tfm;
+
+	char *q;
+	struct scatterlist sg;
+	int ret;
+	u_char buf[16];
+
+	aes_tfm=crypto_alloc_tfm("aes", CRYPTO_TFM_MODE_ECB);
+	if (!aes_tfm) 
+		return -1;
+
+	ret = crypto_cipher_setkey(aes_tfm, sha2 + 0, DM_BDE_KKEYLEN);
+	if (ret) 
+		goto errout;
+
+	sg.page = virt_to_page(input);
+	sg.offset = offset_in_page(input);
+	sg.length = sizeof buf;
+
+	ret = crypto_cipher_decrypt(aes_tfm, &sg, &sg, sizeof buf);
+
+	if (ret)
+		goto errout;
+
+	q = kmap(sg.page) + sg.offset;
+	*output = le64_to_cpup(q);
+
+
+	crypto_free_tfm(aes_tfm);
+	return(0);
+
+ errout: 
+	crypto_free_tfm(aes_tfm);
+	return -1;
+}
+
+
+/*
+ * Find and Encode/Decode lock sectors.
+ *
+ * Security objective: given the pass-phrase, find, decrypt, decode and
+ * validate the lock sector contents.
+ *
+ * For ondisk metadata we cannot know beforehand which of the lock sectors
+ * a given pass-phrase opens so we must try each of the metadata copies in
+ * sector zero in turn.  If metadata was passed as an argument, we don't
+ * have this problem.
+ *
+ */
+
+int
+dm_bde_decrypt_lockx(struct dm_target *ti, struct dm_bde_softc *sc, u_char *meta, uint64_t mediasize, u_int sectorsize, u_int *nkey)
+{
+	u_char *buf, *q;
+	struct dm_bde_key *gl;
+	struct crypto_tfm *aes_tfm;
+	struct scatterlist sg;
+
+	uint64_t off, q1, sector;
+	uint32_t mod;
+	struct page *page;
+	int error, m, i;
+	unsigned int iv_size;
+	u8 *iv;
+
+	gl = &sc->key;
+
+
+	/* Try to decrypt the metadata */
+
+	error = dm_bde_keyloc_decrypt(sc->sha2, meta, &off);
+	if (error)
+		return error;
+
+	/* If it points ito thin blue air, forget it */
+	if (off + DM_BDE_LOCKSIZE > mediasize) {
+		off = 0;
+		return -EINVAL;
+	}
+
+	/* The lock data may span two physical sectors. */
+
+	m = 1;
+	mod=do_div(off, sectorsize);
+	sector=off;
+
+	if (mod > sectorsize - DM_BDE_LOCKSIZE)
+		m++;
+
+	/* Read the suspected sector(s) */
+
+	page = alloc_page(GFP_KERNEL | GFP_NOIO);
+	if(page == NULL)
+		return -ENOMEM;
+
+	buf = page_address(page);
+	error = dm_read_data(ti, sector, m*sectorsize, buf, mod, DM_BDE_LOCKSIZE);
+
+	if(error)
+		goto errout1;
+
+	/* Find the byte-offset of the stored byte sequence */
+	q = buf;
+
+	/* If it is all zero, somebody nuked our lock sector */
+	q1 = 0;
+	for (i = 0; i < DM_BDE_LOCKSIZE; i++)
+		q1 += q[i];
+	if (q1 == 0) {
+		off = 0;
+		error=ESRCH;
+		goto errout1;
+	}
+
+	/* Decrypt the byte-sequence in place */
+	aes_tfm=crypto_alloc_tfm("aes", CRYPTO_TFM_MODE_CBC);
+	if (!aes_tfm) {
+		error=ENOMEM;
+		goto errout1;
+	}
+
+	error = crypto_cipher_setkey(aes_tfm, sc->sha2 + 16, 32);
+	if (error)
+		goto errout2;
+	
+	iv_size=crypto_tfm_alg_ivsize (aes_tfm);
+	iv=kmalloc(iv_size, GFP_KERNEL);
+	if(!iv) {
+		error=ENOMEM;
+		goto errout2;
+	}
+       
+	memset(iv,0,iv_size);
+	crypto_cipher_set_iv(aes_tfm, iv, iv_size);
+
+	sg.page = page;
+	sg.offset = 0;
+	sg.length = DM_BDE_LOCKSIZE;
+
+	error = crypto_cipher_decrypt(aes_tfm, &sg, &sg, DM_BDE_LOCKSIZE);
+
+	if (error)
+		goto errout3;
+
+	q = kmap(sg.page) + sg.offset;
+
+
+	/* Decode the byte-sequence */
+	i = dm_bde_decode_lock(sc, gl, q);
+
+	q = NULL;
+	if (i < 0) {
+		off = 0;
+		error=EINVAL; //(EDOOFUS);	/* Programming error */
+		goto errout3;
+	} else if (i > 0) {
+		off = 0;
+		error=ENOTDIR; 
+		goto errout3;
+	}
+
+	memset(buf, 0, sectorsize * m);
+
+	/* If the masterkey is all zeros, user destroyed it */
+	q1 = 0;
+	for (i = 0; i < (int)sizeof(gl->mkey); i++)
+		q1 += gl->mkey[i];
+	if (q1 == 0) {
+		error=ENOENT;
+		goto errout3;
+	}
+
+	/* If we have an unsorted lock-sequence, refuse */
+	if (gl->lsector[0] > gl->lsector[1] ||
+	    gl->lsector[1] > gl->lsector[2] ||
+	    gl->lsector[2] > gl->lsector[3])
+		return EINVAL;
+
+	/* Finally, find out which key was used by matching the byte offset */
+	for (i = 0; i < DM_BDE_MAXKEYS; i++)
+		if (nkey != NULL && off == gl->lsector[i])
+			*nkey = i;
+	off = 0;
+	
+	error=0;
+
+ errout3: 
+	kfree(iv);
+
+ errout2:
+	crypto_free_tfm(aes_tfm);
+	
+ errout1:
+	__free_pages(page,0);
+	return error;
+}
+
+
+int
+dm_bde_decrypt_lock(struct dm_target *ti, struct dm_bde_softc *sc, u_char *keymat, u_char *meta, uint64_t mediasize, u_int sectorsize, u_int *nkey)
+{
+	u_char *buf, buf1[16];
+	int error, e, i;
+
+	/* set up the key-material */
+	memcpy(sc->sha2, keymat, SHA512_DIGEST_LENGTH);
+
+
+	/* If passed-in metadata is non-zero, use it */
+	memset(buf1, 0, sizeof buf1);
+//	if (meta != NULL && memcmp(buf1, meta, sizeof buf1))
+//		return (dm_bde_decrypt_lockx(ti, sc, meta, mediasize, sectorsize, nkey));
+
+	
+	/* Read sector zero */
+	buf = kmalloc(sectorsize, GFP_KERNEL | GFP_NOIO);
+	if(buf == NULL)
+		return -ENOMEM;
+
+	error = dm_read_data(ti, 0, sectorsize, buf, 0, sectorsize);
+
+	if (error)
+		return(error);
+
+	/* Try each index in turn, save indicative errors for final result */
+	error = EINVAL;
+	for (i = 0; i < DM_BDE_MAXKEYS; i++) {
+		e = dm_bde_decrypt_lockx(ti, sc, buf + i * 16, mediasize, sectorsize, nkey);
+
+
+		/* Success or destroyed master key terminates */
+		if (e == 0 || e == ENOENT) {
+			error = e;
+			break;
+		}
+		if (e != 0 && error == EINVAL)
+			error = e;
+	}
+	kfree(buf);
+	return (error);
+}
+
diff -Naur linux-2.6.8/drivers/md/dm-bde/dm_bde_main.c linux-2.6.8-dmbde/drivers/md/dm-bde/dm_bde_main.c
--- linux-2.6.8/drivers/md/dm-bde/dm_bde_main.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.8-dmbde/drivers/md/dm-bde/dm_bde_main.c	2005-11-20 13:39:23.510876976 +0100
@@ -0,0 +1,708 @@
+/* Hey Emacs, take a hint: -*- linux-c -*-
+ *
+ * Copyright (C) 2005 Thomas S. Iversen <zensonic@diku.dk>
+ *
+ * This file is released under the GPL.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/bio.h>
+#include <linux/blkdev.h>
+#include <linux/namei.h>
+#include <linux/genhd.h>
+#include <linux/mempool.h>
+#include <linux/slab.h>
+#include <linux/crypto.h>
+#include <linux/workqueue.h>
+#include <asm/atomic.h>
+#include <linux/proc_fs.h>
+#include <asm/scatterlist.h>
+
+#undef PERFORMANCETEST
+//#define PERFORMANCETEST 1
+
+#include "../dm.h"
+#include "dm_bde.h"
+
+
+static struct proc_dir_entry *dmbde;
+
+#ifdef PERFORMANCETEST
+struct dm_bde_work *pwp;
+#endif
+
+/*
+ * Convert a device path to a dev_t.
+ */
+static int lookup_device(const char *path, dev_t *dev)
+{
+	int r;
+	struct nameidata nd;
+	struct inode *inode;
+
+	if ((r = path_lookup(path, LOOKUP_FOLLOW, &nd)))
+		return r;
+
+	inode = nd.dentry->d_inode;
+	if (!inode) {
+		r = -ENOENT;
+		goto out;
+	}
+
+	if (!S_ISBLK(inode->i_mode)) {
+		r = -ENOTBLK;
+		goto out;
+	}
+
+	*dev = inode->i_rdev;
+
+ out:
+	path_release(&nd);
+	return r;
+}
+
+
+
+/* 
+ * memory caches for the system.
+ * 
+ */
+
+static kmem_cache_t *_dm_bde_io_cache;
+static kmem_cache_t *_dm_bde_keysector_cache;
+static kmem_cache_t *_dm_bde_sector_cache;
+static kmem_cache_t *_struct_dm_bde_sector_cache;
+static kmem_cache_t *_dm_bde_wp_cache;
+
+static void * mempool_alloc_page(int gfp_mask, void *data)
+{
+	return alloc_page(gfp_mask);
+}
+
+static void mempool_free_page(void *page, void *data)
+{
+	__free_page(page);
+}
+
+
+/*
+ * workqueue (kdmbded)
+ *
+ */
+struct workqueue_struct *_kdmbded_workqueue;
+
+static int proc_read_dmbde(char *page, char **start,
+			    off_t off, int count, 
+			    int *eof, void *data)
+{
+	int len=0;
+	struct dm_bde_softc *sc = (struct dm_bde_softc *)data;
+
+	len += sprintf(page+len, "\nKeysector release statistics\n\n");
+	len += sprintf(page+len, "Number of keysector_release calls: %lu\n",sc->ksp_releases);
+	len += sprintf(page+len, "Number of elements fetched in keysectorlist in release: %lu\n",sc->ksp_newowner_search);
+	len += sprintf(page+len, "Number of elements fetched which resulted in new owner being found: %lu\n",sc->ksp_newowner_found);
+
+	len += sprintf(page+len, "\nNumber of requests in question\n\n");
+	len += sprintf(page+len, "Number of wp allocated %lu\n",sc->wp_allocated);
+	len += sprintf(page+len, "Number of submitted sector reads was %lu\n",sc->sector_reads);
+	len += sprintf(page+len, "Number of submitted keysector reads was %lu\n",sc->keysector_reads);
+	len += sprintf(page+len, "Number of map calls %lu\n",sc->number_of_map_calls);
+
+	len += sprintf(page+len, "\nEncrypt calls\n\n");
+	len += sprintf(page+len, "Time spent encrypting %lu\n",sc->time_spent_encrypting);
+	len += sprintf(page+len, "Bytes encrypted %lu\n",sc->encrypt_bytes);
+
+
+	return len;
+}
+
+static int proc_write_dmbde(struct file *file,
+			     const char *buffer,
+			     unsigned long count, 
+			     void *data)
+{
+	struct dm_bde_softc *sc = (struct dm_bde_softc *)data;
+	sc->sleep_accumulated=0;
+	sc->no_new_sector=0;
+	sc->ksp_newowner_found=0;
+	sc->ksp_newowner_search=0;
+	sc->ksp_releases=0;
+	sc->time_spent_encrypting=0;
+	sc->encrypt_bytes=0;
+
+	sc->wp_allocated=0;
+	sc->fetched_wp=0;
+	sc->wasted_io=0;
+	sc->wasted_notowner=0;
+	sc->wasted_wait=0;
+
+	sc->sector_reads=0;
+	sc->keysector_reads=0;
+	sc->work_todo = 0;
+	sc->worklistscans = 0;
+	sc->number_of_map_calls=0;
+
+	return count;
+
+}
+
+
+/*
+ * Decode key from its hex representation
+ */
+static int crypt_decode_key(u8 *key, char *hex, int size)
+{
+	char buffer[3];
+	char *endp;
+	int i;
+
+	buffer[2] = '\0';
+
+	for(i = 0; i < size; i++) {
+		buffer[0] = *hex++;
+		buffer[1] = *hex++;
+
+		key[i] = (u8)simple_strtoul(buffer, &endp, 16);
+
+		if (endp != &buffer[2])
+			return -EINVAL;
+	}
+
+	if (*hex != '\0')
+		return -EINVAL;
+
+	return 0;
+}
+static int dm_bde_ctr(struct dm_target *ti, unsigned int argc, char **argv)
+{
+	dev_t dev;
+	struct gendisk *gdp;
+	int n;
+	int error;
+
+	char *path;
+	unsigned char *key;
+	unsigned char *pass;
+	int passsize;
+	struct dm_bde_softc *sc;
+	struct dm_bde_key *kp;
+
+	u_int sectorsize;
+	uint64_t mediasize=0;
+
+	sc = kmalloc(sizeof(struct dm_bde_softc), GFP_KERNEL);
+	memset(sc,0,sizeof(*sc));
+
+	if (sc == NULL) {
+		ti->error = BDE "can not allocate context";
+		return -ENOMEM;
+	}
+
+	init_waitqueue_head(&sc->waitq);
+
+	sc->no_new_sector=0;
+	sc->sleep_accumulated=0;
+	sc->time_spent_encrypting=0;
+	sc->encrypt_bytes=0;
+
+	sc->decrypts=0;
+	sc->ksp_releases=0;
+	sc->ksp_newowner_search=0;
+	sc->ksp_newowner_found=0;
+
+	sc->wp_allocated=0;
+	sc->fetched_wp=0;
+	sc->wasted_io=0;
+	sc->wasted_notowner=0;
+	sc->wasted_wait=0;
+
+	sc->sector_reads=0;
+	sc->keysector_reads=0;
+	sc->work_todo = 0;
+	sc->worklistscans = 0;
+	sc->number_of_map_calls=0;
+
+
+	ti->error = BDE "Not enough arguments";
+	if(argc < 2)
+		goto errout;
+	path=argv[0];
+
+	passsize = strlen(argv[1]) >> 1;
+	if(!passsize) {
+		ti->error = BDE "no passphrase presented to dmbde";
+		goto errout;
+	}
+
+	pass=kmalloc(passsize, GFP_KERNEL);
+	if(!pass) {
+		ti->error = BDE "kmalloc error";
+		goto errout;
+	}
+
+	if(crypt_decode_key(pass, argv[1], passsize) < 0) {
+		ti->error = BDE "Could not decode passphrase";
+		goto errout1;
+	}
+
+	if(argc == 3)
+		key=argv[2]; 
+
+	if(lookup_device(path,&dev)) {
+		ti->error = BDE "Device lookup failed";
+		goto errout1;
+	}
+
+	if (dm_get_device(ti, path, 0, ti->len,
+	                  dm_table_get_mode(ti->table), &sc->dev)) {
+		ti->error = BDE "Device lookup failed";
+		goto errout1;
+	} 
+
+	sc->io_pool = mempool_create(MIN_IOS, mempool_alloc_slab,
+				     mempool_free_slab, _dm_bde_io_cache);
+	if (!sc->io_pool) {
+		ti->error = BDE "Cannot allocate io mempool";
+		goto errout2;
+	}
+
+	sc->sector_pool = mempool_create(MIN_SECTORS, mempool_alloc_slab,
+				     mempool_free_slab, _dm_bde_sector_cache);
+	if (!sc->sector_pool) {
+		ti->error = BDE "Cannot allocate sector mempool";
+		goto errout3;
+	}
+
+	sc->struct_sector_pool = mempool_create(MIN_SECTOR_STRUCTS, mempool_alloc_slab,
+				     mempool_free_slab, _struct_dm_bde_sector_cache);
+	if (!sc->struct_sector_pool) {
+		ti->error = BDE "Cannot allocate sector mempool";
+		goto errout4;
+	}
+
+	sc->wp_pool = mempool_create(MIN_WPS, mempool_alloc_slab,
+				     mempool_free_slab, _dm_bde_wp_cache);
+	if (!sc->wp_pool) {
+		ti->error = BDE "Cannot allocate Work Packet mempool";
+		goto errout5;
+	}
+
+	sc->page_pool = mempool_create(MIN_POOL_PAGES, mempool_alloc_page,
+				       mempool_free_page, NULL);
+	if (!sc->page_pool) {
+		ti->error = BDE "Cannot allocate page mempool";
+		goto errout6;
+	}
+
+	INIT_LIST_HEAD(&sc->worklist);
+
+	init_MUTEX(&sc->worklist_mutex);
+
+	INIT_LIST_HEAD(&sc->freelist);
+
+	ti->private = sc;
+
+	gdp=sc->dev->bdev->bd_disk;
+	sectorsize=bdev_hardsect_size(sc->dev->bdev);
+
+	for (n = 0; n < gdp->minors - 1; n++) {
+                if (!gdp->part[n])
+                        continue;
+                if (gdp->part[n]->nr_sects == 0)
+                        continue;
+		/* FIXME: is this ok if partions are numbered out order? */
+
+		if(gdp->major == MAJOR(dev)  && n + 1 + gdp->first_minor == MINOR(dev)) {
+			mediasize=gdp->part[n]->nr_sects * sectorsize;
+			break;
+		}
+        }
+
+
+
+	ddprintk(BDE "Hardsect: %d\n",sectorsize);
+	ddprintk(BDE "Mediasize: %llu\n", mediasize);
+	ddprintk(BDE "Alternative mediasize %llu\n",(unsigned long long)sc->dev->bdev->bd_inode->i_size >> SECTOR_SHIFT);
+
+	key = NULL;
+	error=dm_bde_decrypt_lock(ti, sc, pass, key, mediasize, sectorsize, NULL);
+	memset(sc->sha2, 0, sizeof sc->sha2);
+	if (error) {	
+		ti->error = BDE "Could not decrypt lock";
+		goto errout7;
+	}
+	kp = &sc->key;
+
+	/* Initialize helper-fields */
+	kp->keys_per_sector = kp->sectorsize / DM_BDE_SKEYLEN;
+	kp->zone_cont = kp->keys_per_sector * kp->sectorsize;
+	kp->zone_width = kp->zone_cont + kp->sectorsize;
+	kp->media_width = kp->sectorN - kp->sector0 -
+		DM_BDE_MAXKEYS * kp->sectorsize;
+	
+	ddprintk(BDE "kp->sectorsize(%d), kp->keys_per_sector(%d), kp->zone_cont(%lld), kp->zone_width(%lld), kp->media_width(%lld), kp->sectorN(%lld), kp->sector0(%lld)\n",kp->sectorsize, kp->keys_per_sector, (unsigned long long)kp->zone_cont, (unsigned long long)kp->zone_width, (unsigned long long)kp->media_width, (unsigned long long)kp->sectorN, (unsigned long long)kp->sector0);
+
+	/* Our external parameters */
+	sc->zone_cont = kp->zone_cont;
+	sc->mediasize = dm_bde_max_sector(kp);
+	sc->sectorsize = kp->sectorsize;
+
+	_dm_bde_keysector_cache = kmem_cache_create("dm_bde_keysector", sc->sectorsize, 0, 0, NULL, NULL);
+	if (!_dm_bde_keysector_cache) {
+		printk("Cannot create keysector cache\n");
+		goto errout7;
+	}
+
+	sc->keysector_pool = mempool_create(MIN_KEYSECTORS, mempool_alloc_slab,
+				     mempool_free_slab, _dm_bde_keysector_cache);
+	if (!sc->keysector_pool) {
+		ti->error = BDE "Cannot allocate keysector mempool";
+		goto errout8;
+	}
+
+	/* Start worker thread */
+
+#ifndef PERFORMANCETEST
+	kdmbded_queue_work(sc);
+
+#else
+	pwp = dm_bde_new_work(sc);
+	if (pwp == NULL) {
+		printk("Cannot allocate work struct for performance measures\n");
+		goto errout9;
+	}
+
+	pwp->ko = 0;
+	pwp->offset = 0;
+	pwp->so=0;
+	pwp->ksp=dm_bde_new_sector(pwp,4096);
+	if(!pwp->ksp) {
+		printk("Could not allocate pwp->ksp\n");
+		goto errout10;
+	}
+
+	pwp->bi_vcnt = 16;
+	pwp->bi_io_vec=kmalloc(sizeof(struct bio_vec)*pwp->bi_vcnt, GFP_KERNEL);
+	if(!pwp->bi_io_vec) {
+		printk("Could not allocate pwp->bi_io_vec\n");
+		goto errout11;
+	}
+
+	int i;
+
+	for(i=0; i< pwp->bi_vcnt;i++) {
+		pwp->bi_io_vec[i].bv_page = alloc_page(GFP_KERNEL);
+		pwp->bi_io_vec[i].bv_len = PAGE_SIZE;
+		pwp->bi_io_vec[i].bv_offset = 0;
+		if(!pwp->bi_io_vec[i].bv_page) {
+			printk("Could not allocate pages\n");
+			goto errout11;
+		}
+	}
+
+	pwp->sp=dm_bde_new_sector(pwp,0);
+	if(!pwp->sp) {
+		printk("Could not allocate pwp->sp\n");
+		goto errout12;
+	}
+
+	pwp->sp->bi_io_vec=kmalloc(sizeof(struct bio_vec)*pwp->bi_vcnt, GFP_KERNEL);
+	if(!pwp->sp->bi_io_vec) {
+		printk("Could not allocate pwp->sp->bi_io_vec\n");
+		goto errout13;
+	}
+
+
+	int k;
+	for(k=0; k< pwp->bi_vcnt;k++) {
+		pwp->sp->bi_io_vec[k].bv_page = alloc_page(GFP_KERNEL);
+		pwp->sp->bi_io_vec[k].bv_len = PAGE_SIZE;
+		pwp->sp->bi_io_vec[k].bv_offset = 0;
+		if(!pwp->sp->bi_io_vec[k].bv_page) {
+			printk("Could not allocate pages\n");
+			goto errout14;
+		}
+	}
+
+	int j,l;
+	int count = 1000;
+	int sizes[] = {512,1024,2048,4096,0};
+
+	for(j=0;;j++) {
+		if(!sizes[j])
+			break;
+		sc->sectorsize = sizes[j];
+
+		unsigned long jiffies1 = jiffies;
+		for(l=0;l<count;l++)
+			dm_bde_crypt_read(pwp);
+
+		printk(BDE "sectorsize (%d): decrypted %lu bytes in %lu\n", sizes[j], count * PAGE_SIZE * pwp->bi_vcnt, jiffies - jiffies1);
+	}
+
+	for(j=0;;j++) {
+		if(!sizes[j])
+			break;
+		sc->sectorsize = sizes[j];
+
+		unsigned long jiffies1 = jiffies;
+		for(l=0;l<count;l++)
+			dm_bde_crypt_write(pwp);
+
+		printk(BDE "sectorsize (%d): ENcrypted %lu bytes in %lu\n", sizes[j], count * PAGE_SIZE * pwp->bi_vcnt, jiffies - jiffies1);
+	}
+	sc->sectorsize = kp->sectorsize;
+#endif
+
+	/* create proc entry */
+
+	dmbde = create_proc_entry("dmbde", S_IWUSR | S_IRUGO, &proc_root);
+	if (!dmbde)
+		goto errout14;
+
+	dmbde->owner = THIS_MODULE;
+	dmbde->read_proc = proc_read_dmbde;
+	dmbde->write_proc = proc_write_dmbde;
+	dmbde->data = sc;
+
+	printk(BDE "Device %s (%d,%d) attached\n",path,MAJOR(dev),MINOR(dev));
+
+	/* ensure that we only get request >= sc->sectorsize */
+
+	ti->limits.hardsect_size = sc->sectorsize;
+
+	return 0;
+
+	/* clean up own allocations */
+ errout14:
+#ifdef PERFORMANCETEST
+	for( ; k >= 0 ; k--)
+		__free_pages(pwp->sp->bi_io_vec[k].bv_page,0);
+	kfree(pwp->sp->bi_io_vec);
+ errout13:
+	dm_bde_delete_sector(sc, pwp->sp);
+ errout12:
+	for( ; i >= 0 ; i--)
+		__free_pages(pwp->bi_io_vec[i].bv_page,0);
+ errout11:
+	dm_bde_delete_sector(sc, pwp->ksp);
+ errout10:
+	dm_bde_delete_work(pwp);
+ errout9:
+#endif
+	mempool_destroy(sc->keysector_pool);
+ errout8:
+	kmem_cache_destroy(_dm_bde_keysector_cache);
+ errout7:
+	mempool_destroy(sc->page_pool);
+ errout6:
+	mempool_destroy(sc->wp_pool);
+ errout5:
+	mempool_destroy(sc->struct_sector_pool);
+ errout4:
+	mempool_destroy(sc->sector_pool);
+ errout3:
+	mempool_destroy(sc->io_pool);
+ errout2:
+	dm_put_device(ti, sc->dev);
+ errout1:
+	kfree(pass);
+ errout:
+	kfree(sc);	
+	return -EINVAL;
+
+}
+
+static void dm_bde_dtr(struct dm_target *ti)
+{
+
+	struct dm_bde_softc *sc = (struct dm_bde_softc *) ti->private;
+
+
+	/* First we stop the work thread and wait for pending IO */
+	 
+	sc->dead = 1;
+	flush_workqueue(_kdmbded_workqueue);
+
+	/* clean up allocations from dm_bde_ctr */
+
+	remove_proc_entry("dmbde", NULL);
+
+#ifdef PERFORMANCETEST
+	int k;
+	for(k=0;k<pwp->bi_vcnt ; k++)
+		__free_pages(pwp->sp->bi_io_vec[k].bv_page,0);
+	kfree(pwp->sp->bi_io_vec);
+	dm_bde_delete_sector(sc, pwp->sp);
+
+	int i;
+	for(i=0; i< pwp->bi_vcnt;i++)
+		__free_pages(pwp->bi_io_vec[i].bv_page,0);
+	dm_bde_delete_sector(sc, pwp->ksp);
+	dm_bde_delete_work(pwp);
+#endif
+
+	mempool_destroy(sc->keysector_pool);
+ 
+	kmem_cache_destroy(_dm_bde_keysector_cache);
+
+	ddprintk(BDE "Destroying page pool\n");
+	mempool_destroy(sc->page_pool);
+
+	ddprintk(BDE "Destroying wp_pool\n");
+	mempool_destroy(sc->wp_pool);
+
+	ddprintk(BDE "Destroying struct sector_pool\n");
+	mempool_destroy(sc->struct_sector_pool);
+
+	ddprintk(BDE "Destroying sector_pool\n");
+	mempool_destroy(sc->sector_pool);
+
+	ddprintk(BDE "Destroying io_pool\n");
+	mempool_destroy(sc->io_pool);
+ 
+	printk(BDE "Device detached\n");
+	dm_put_device(ti, sc->dev);
+
+	ddprintk(BDE "About to free sc\n");
+	kfree(sc);
+
+
+}
+
+
+static int dm_bde_map(struct dm_target *ti, struct bio *bio,
+		     union map_info *map_context)
+{
+
+	struct dm_bde_softc *sc = (struct dm_bde_softc *) ti->private;
+	struct dm_bde_io *io;
+
+	while(!(io=mempool_alloc(sc->io_pool, GFP_NOIO)))
+		blk_congestion_wait(bio_data_dir(bio), HZ/100);
+
+	bio->bi_bdev = sc->dev->bdev;
+	dm_bde_start1(ti, bio, io);
+	return 0;
+}
+
+
+static int dm_bde_status(struct dm_target *ti, status_type_t type,
+			char *result, unsigned int maxlen)
+{
+	int offset;
+	switch (type) {
+	case STATUSTYPE_INFO:
+		result[0] = '\0';
+		break;
+
+	case STATUSTYPE_TABLE:
+		offset = scnprintf(result, maxlen, "Thomas");
+	}
+
+	return 0;
+}
+
+static struct target_type dm_bde_target = {
+	.name   = "dm_bde",
+	.version= {1, 0, 0},
+	.module = THIS_MODULE,
+	.ctr    = dm_bde_ctr,
+	.dtr    = dm_bde_dtr,
+	.map    = dm_bde_map,
+	.status = dm_bde_status,
+};
+
+
+
+static int __init dm_bde_init(void)
+{
+	int err = 0;
+	_dm_bde_io_cache = kmem_cache_create("dm_bde_io", sizeof(struct dm_bde_io), 0, 0, NULL, NULL);
+	if (!_dm_bde_io_cache) 
+	        return -ENOMEM;
+
+	_dm_bde_sector_cache = kmem_cache_create("dm_bde_sector", PAGE_SIZE, 0, 0, NULL, NULL);
+	if (!_dm_bde_sector_cache) {
+		err = -ENOMEM;
+		goto errout1;
+	}
+
+	_struct_dm_bde_sector_cache = kmem_cache_create("struct_dm_bde_sector", sizeof(struct dm_bde_sector), 0, 0, NULL, NULL);
+	if (!_struct_dm_bde_sector_cache) {
+		err = -ENOMEM;
+		goto errout2;
+	}
+
+	_dm_bde_wp_cache = kmem_cache_create("dm_bde_wp", sizeof(struct dm_bde_work), 0, 0, NULL, NULL);
+	if (!_dm_bde_wp_cache) {
+		err = -ENOMEM;
+		goto errout3;
+	}
+
+	_kdmbded_workqueue = create_workqueue("kdmbded");
+	if (!_kdmbded_workqueue) {
+		err = -ENOMEM;
+
+		DMERR(BDE "Could not create kdmbded workqueue");
+		goto errout4;
+	}
+
+	err = dm_register_target(&dm_bde_target);
+	if (err < 0) {
+		DMERR(BDE "Could not register dm_bde target(%d)", err);
+		goto errout5;
+	}
+
+	printk(BDE "Sucessfully initialized dmbde\n");
+	return 0;
+
+errout5:
+	destroy_workqueue(_kdmbded_workqueue);
+errout4:
+	kmem_cache_destroy(_dm_bde_wp_cache);
+errout3:
+	kmem_cache_destroy(_struct_dm_bde_sector_cache);
+errout2:
+	kmem_cache_destroy(_dm_bde_sector_cache);
+errout1:
+	kmem_cache_destroy(_dm_bde_io_cache);
+	return err;
+}
+
+static void __exit dm_bde_exit(void)
+{
+	int err = dm_unregister_target(&dm_bde_target);
+	ddprintk(BDE "dm_bde_exit called\n");
+
+	if (err < 0)
+		DMERR(BDE "unregister failed %d", err);
+
+	ddprintk(BDE "destroy workqueue\n");
+	destroy_workqueue(_kdmbded_workqueue);
+
+	ddprintk(BDE "destroy sector cache\n");
+	kmem_cache_destroy(_dm_bde_sector_cache);
+
+	ddprintk(BDE "destroy io cache\n");
+	kmem_cache_destroy(_dm_bde_io_cache);
+
+	ddprintk(BDE "destroy wp cache\n");
+	kmem_cache_destroy(_dm_bde_wp_cache);
+
+	ddprintk(BDE "destroy struct sector cache\n");
+	kmem_cache_destroy(_struct_dm_bde_sector_cache);
+
+	printk(BDE "Sucessfully removed dmbde\n");
+}
+
+
+module_init(dm_bde_init);
+module_exit(dm_bde_exit);
+
+MODULE_AUTHOR("Thomas S. Iversen <thomassi@dina.kvl.dk>");
+MODULE_DESCRIPTION(DM_NAME "target for transparent FreeBSD like (GDBE) encryption / decryption");
+MODULE_LICENSE("GPL");
diff -Naur linux-2.6.8/drivers/md/dm-bde/dm_bde_work.c linux-2.6.8-dmbde/drivers/md/dm-bde/dm_bde_work.c
--- linux-2.6.8/drivers/md/dm-bde/dm_bde_work.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.8-dmbde/drivers/md/dm-bde/dm_bde_work.c	2005-11-20 13:45:02.822293800 +0100
@@ -0,0 +1,1018 @@
+/* Hey Emacs, take a hint: -*- linux-c -*-
+ *
+ * dm_bde_work.c is a part of the Linux port of GBDE from FreeBSD, written by 
+ * Poul-Henning Kamp (PHK). Permission has been given by PHK to release 
+ * this software under GPL, as long as the original BSD licence is included
+ * in the source.
+ *
+ * dm_bde_work.c is 
+ * Copyright (c) 2004-2005 Thomas S. Iversen and
+ * Copyright (c) 2002 Poul-Henning Kamp
+ * Copyright (c) 2002 Networks Associates Technology, Inc.
+ * All rights reserved.
+ *        
+ *
+ *                     - GPL Licence -
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.		    
+ *
+ *
+ *                     - BSD Licence -
+ *
+ * This software was developed for the FreeBSD Project by Poul-Henning Kamp
+ * and NAI Labs, the Security Research Division of Network Associates, Inc.
+ * under DARPA/SPAWAR contract N66001-01-C-8035 ("CBOSS"), as part of the
+ * DARPA CHATS research program.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * Source location: drivers/md/dm-bde.c
+ *
+ * This source file contains the state-engine which makes things happen in the
+ * right order.
+ *
+ * Outline:
+ *   1) dm_bde_start1()
+ *	Break the struct bio into multiple work packets one per zone.
+ *   2) dm_bde_start2()
+ *	Setup the necessary sector buffers and start those read operations
+ *	which we can start at this time and put the item on the work-list.
+ *   3) dm_bde_worker()
+ *	Scan the work-list for items which are ready for crypto processing
+ *	and call the matching crypto function in dm_bde_crypt.c and schedule
+ *	Any writes needed.  Read operations finish here by releasing the
+ *	sector buffers and delivering the original bio request.
+ *   4) dm_bde_write_done()
+ *	Release sector buffers and deliver the original bio request.
+ *
+ * Because of the C-scope rules, the functions are almost perfectly in the
+ * opposite order in this source file.
+ *
+ * XXX: A switch to the hardware assisted crypto in src/sys/opencrypto will add
+ * XXX: additional states to this state-engine.  Since no hardware available
+ * XXX: at this time has AES support, implementing this has been postponed
+ * XXX: until such time as it would result in a benefit.
+ */
+
+#include <linux/crypto.h>
+#include <asm/div64.h>
+#include "../dm.h"
+#include "dm_bde.h"
+#include <linux/bio.h>
+
+static u_int dm_bde_nwork;
+
+/*
+ * Mempool alloc and free functions for the page
+ */
+
+struct dm_bde_work *
+dm_bde_new_work(struct dm_bde_softc *sc)
+{
+	struct dm_bde_work *wp;
+
+	wp=mempool_alloc(sc->wp_pool, GFP_KERNEL);
+
+	if (wp == NULL)
+		return (wp);
+
+	memset(wp,0, sizeof *wp);
+
+	wp->state = SETUP;
+	wp->softc = sc;
+	dm_bde_nwork++;
+	sc->nwork++;
+
+	list_add_tail(&wp->list, &sc->worklist);
+	return (wp);
+}
+
+void
+dm_bde_delete_work(struct dm_bde_work *wp)
+{
+	struct dm_bde_softc *sc;
+
+	sc = wp->softc;
+	dm_bde_nwork--;
+	sc->nwork--;
+	list_del(&wp->list);
+	if(wp->bi_io_vec)
+		kfree(wp->bi_io_vec);
+	mempool_free(wp, sc->wp_pool);
+}
+
+static u_int dm_bde_nsect;
+
+void
+dm_bde_delete_sector(struct dm_bde_softc *sc, struct dm_bde_sector *sp)
+{
+	dm_bde_nsect--;
+	sc->nsect--;
+	if(sp->malloc) {
+		sc->nsectdata--;
+		mempool_free(sp->sectordata, sc->keysector_pool);
+		kfree(sp->bi_io_vec);
+	}
+	mempool_free(sp, sc->struct_sector_pool);
+
+//	kfree(sp);
+}
+
+
+struct dm_bde_sector *
+dm_bde_new_sector(struct dm_bde_work *wp, u_int len)
+{
+	struct dm_bde_softc *sc = wp->softc;
+	struct dm_bde_sector *sp;
+
+	if(sc->nsect > 100) 
+		/* Cachelimit */
+		return NULL;
+
+//	sp = kmalloc(sizeof *sp, GFP_KERNEL);	
+	sp = mempool_alloc(sc->struct_sector_pool, GFP_KERNEL);
+	if (sp == NULL)
+		return (sp);
+
+	sp->sectordata=NULL;
+	sp->malloc=0;
+	sp->bi_io_vec = NULL;
+	sp->bi_vcnt = 0;
+
+	if (len > 0) {
+		sp->sectordata = mempool_alloc(sc->keysector_pool, GFP_KERNEL);
+
+		if(!sp->sectordata) {
+//			kfree(sp);
+			mempool_free(sp, sc->struct_sector_pool);
+			return NULL;
+		}
+		sp->bi_io_vec = kmalloc(sizeof(struct bio_vec), GFP_KERNEL);
+		if(!sp->bi_io_vec) {
+			mempool_free(sp->sectordata, sc->keysector_pool);
+			mempool_free(sp, sc->struct_sector_pool);
+//			kfree(sp);
+			return NULL;
+		}
+		sp->bi_vcnt = 1;
+
+		sp->bi_io_vec[0].bv_page = virt_to_page(sp->sectordata);
+		sp->bi_io_vec[0].bv_offset = offset_in_page(sp->sectordata);
+		sp->bi_io_vec[0].bv_len = len;
+
+		sp->malloc = 1;
+		sc->nsectdata++;
+	}
+
+	dm_bde_nsect++;
+	wp->softc->nsect++;
+	sp->size = len;
+	sp->softc = wp->softc;
+	sp->ref = 1;
+	sp->owner = wp;
+	sp->offset = wp->so;
+	sp->state = JUNK;
+	return (sp);
+}
+
+
+/*
+ * Skey sector cache.
+ *
+ * Nothing prevents two separate I/O requests from addressing the same zone
+ * and thereby needing the same skey sector.  We therefore need to sequence
+ * I/O operations to the skey sectors.  A certain amount of caching is also
+ * desirable, although the extent of benefit from this is not at this point
+ * determined.
+ *
+ */
+
+static u_int dm_bde_ncache;
+
+static void
+dm_bde_purge_one_sector(struct dm_bde_softc *sc, struct dm_bde_sector *sp)
+{
+
+	if (sp->ref != 0)
+		return;
+	list_del(&sp->list);
+	dm_bde_ncache--;
+	sc->ncache--;
+//	memset(sp->data, 0, sp->size);
+	dm_bde_delete_sector(sc, sp);
+}
+
+
+
+static struct dm_bde_sector *
+dm_bde_get_keysector(struct dm_bde_work *wp)
+{
+	struct dm_bde_sector *sp;
+	struct dm_bde_softc *sc;
+	struct list_head *lhp;
+	uint64_t offset;
+
+	offset = wp->kso;
+	sc = wp->softc;
+
+#if 0
+	if (malloc_last_fail() < dm_bde_ncache)
+		dm_bde_purge_sector(sc, -1);
+#endif 
+	lhp = sc->freelist.next;
+	if(lhp != &sc->freelist) {
+		sp = list_entry(sc->freelist.next, struct dm_bde_sector, list);
+		if (sp->ref == 0 && time_before(sp->used + 300 * HZ, jiffies))
+			dm_bde_purge_one_sector(sc, sp);
+	}
+	
+	list_for_each(lhp, &sc->freelist) {
+		sp = list_entry(lhp, struct dm_bde_sector, list);
+		if (sp->offset == offset)
+			break;
+	}
+
+	if(lhp == &sc->freelist)
+		sp = NULL;
+
+
+	if (sp != NULL) {
+		sp->ref++;
+		KASSERT(sp->offset == offset, ("wrong offset"));
+		KASSERT(sp->softc == wp->softc, ("wrong softc"));
+		if (sp->ref == 1)
+			sp->owner = wp;
+	} else {
+//		if (malloc_last_fail() < dm_bde_ncache) {
+//			TAILQ_FOREACH(sp, &sc->freelist, list)
+//				if (sp->ref == 0)
+//					break;
+//		}
+		if (sp == NULL && !list_empty(&sc->freelist))
+			sp = list_entry(sc->freelist.next, struct dm_bde_sector, list); 
+
+		if (sp != NULL && sp->ref > 0)
+			sp = NULL;
+
+		if (sp == NULL) {
+
+			sp = dm_bde_new_sector(wp, sc->sectorsize);
+			if (sp != NULL) {
+				dm_bde_ncache++;
+				sc->ncache++;
+				list_add_tail(&sp->list, &sc->freelist);
+				sp->malloc = 2;
+			}
+		}
+		if (sp != NULL) {
+			sp->offset = offset;
+			sp->softc = wp->softc;
+			sp->ref = 1;
+			sp->owner = wp;
+			sp->state = JUNK;
+			sp->error = 0;
+		}
+	}
+	if (sp != NULL) {
+		list_del(&sp->list);
+		list_add_tail(&sp->list, &sc->freelist);
+		sp->used = jiffies;
+	}
+
+	wp->ksp = sp;
+	return(sp);
+}
+
+static void
+dm_bde_release_keysector(struct dm_bde_work *wp)
+{
+	struct dm_bde_softc *sc;
+	struct dm_bde_work *wp2=NULL;
+	struct list_head *p2;
+	struct dm_bde_sector *sp;
+
+	sp = wp->ksp;
+	KASSERT(sp->malloc == 2, ("Wrong sector released"));
+	sc = sp->softc;
+
+	KASSERT(sc != NULL, ("NULL sp->softc"));
+	KASSERT(wp == sp->owner, ("Releasing, not owner"));
+	sp->owner = NULL;
+	wp->ksp = NULL;
+	sp->ref--;
+
+	if (sp->ref > 0) {
+		sc->ksp_releases++;
+		list_del(&sp->list);
+		list_add_tail(&sp->list, &sc->freelist);
+
+		list_for_each(p2, &sc->worklist) {
+			sc->ksp_newowner_search++;
+			wp2 = list_entry(p2, struct dm_bde_work, list);
+			if (wp2->ksp == sp) {
+				sc->ksp_newowner_found++;
+				KASSERT(wp2 != wp, ("Self-reowning"));
+				sp->owner = wp2;
+				sc->work_todo=1;
+				wake_up_interruptible(&sc->waitq);
+				break;
+			}
+		}
+		KASSERT(wp2 != NULL, ("Failed to pick up owner for %p\n", sp));
+        } else if (sp->error != 0) {
+		sp->offset = ~0;
+		sp->error = 0;
+		sp->state = JUNK;
+	}
+	list_del(&sp->list);
+	list_add(&sp->list, &sc->freelist);
+}
+
+static void
+dm_bde_purge_sector(struct dm_bde_softc *sc, int fraction)
+{
+	struct dm_bde_sector *sp;
+	struct list_head *lhp;
+	int n;
+
+	if (fraction > 0)
+		n = sc->ncache / fraction + 1;
+	else 
+		n = dm_bde_ncache; // FIXME: need malloc_last_fail - malloc_last_fail();
+	if (n < 0)
+		return;
+	if (n > sc->ncache)
+		n = sc->ncache;
+	while(n--) {
+		list_for_each(lhp, &sc->freelist) {
+			sp = list_entry(lhp, struct dm_bde_sector, list);
+			if (sp->ref != 0)
+				continue;
+			list_del(&sp->list);
+			dm_bde_ncache--;
+			sc->ncache--;
+//			memset(sp->data, 0, sp->size);
+			dm_bde_delete_sector(sc, sp);
+			break;
+		}
+	}
+}
+
+
+static struct dm_bde_sector *
+dm_bde_read_keysector(struct dm_bde_softc *sc, struct dm_bde_work *wp)
+{
+	struct dm_bde_sector *sp;
+
+	sp = dm_bde_get_keysector(wp);
+	if (sp == NULL) {
+		dm_bde_purge_sector(sc, -1);
+		sp = dm_bde_get_keysector(wp);
+	}
+	if (sp == NULL)
+		return (sp);
+
+	if (sp->owner != wp)
+		return (sp);
+
+	if (sp->state == VALID) 
+		return (sp);
+
+	if (dm_bde_start_read(wp, sp) == 0) {
+		sc->keysector_reads++;
+		return (sp);
+	}
+	dm_bde_release_keysector(wp);
+	return (NULL);
+}
+
+
+/*
+ * Contribute to the completion of the original bio request.
+ *
+ * We have no simple way to tell how many bits the original bio request has
+ * been segmented into, so the easiest way to determine when we can deliver
+ * it is to keep track of the number of bytes we have completed.  We keep
+ * track of any errors underway and latch onto the first one.
+ *
+ * We always report "nothing done" in case of error, because random bits here
+ * and there may be completed and returning a number of completed bytes does
+ * not convey any useful information about which bytes they were.  If some
+ * piece of broken code somewhere interprets this to mean that nothing has
+ * changed on the underlying media they deserve the lossage headed for them.
+ *
+ * A single mutex per dm_bde instance is used to prevent contention.
+ */
+
+static void
+dm_bde_contribute(struct dm_bde_work *wp, struct bio *bp, off_t bytes, int error)
+{
+	struct dm_bde_io *io = wp->io;
+	struct dm_bde_softc *sc = wp->softc;
+
+	atomic_add(bytes,&io->completed);
+	if(atomic_read(&io->completed) == bp->bi_size) {
+		bio_endio(bp, bp->bi_size, error);
+		mempool_free(io, sc->io_pool);
+	}
+}
+
+
+/* 
+ * When we have all expected cows in the
+ * barn close the door and call it a day.
+ */
+
+static void dm_bde_write_done_work(void *data)
+{
+
+	struct dm_bde_sector *sp = (struct dm_bde_sector *) data;
+	struct dm_bde_softc *sc = sp->softc;
+	struct dm_bde_work *wp = sp->owner;
+	int i;
+
+	down_interruptible(&sc->worklist_mutex);
+
+	KASSERT(sp != NULL, ("NULL sp"));
+	KASSERT(sc != NULL, ("NULL sc"));
+	KASSERT(sp->owner != NULL, ("NULL sp->owner"));
+
+	if (wp->error == 0)
+		wp->error = sp->error;
+
+	KASSERT(bio_data_dir(wp->bp) == WRITE, ("Confused in dm_bde_write_done()"));
+
+	KASSERT(sp == wp->sp || sp == wp->ksp, ("trashed write op"));
+	if (wp->sp == sp) {
+		for(i = 0 ; i < sp->bi_vcnt ; i++) 
+			__free_pages(sp->bi_io_vec[i].bv_page,0);
+//			mempool_free(sp->bi_io_vec[i].bv_page, sc->page_pool);
+		kfree(sp->bi_io_vec);
+
+		dm_bde_delete_sector(sc, wp->sp);
+		wp->sp = NULL;
+	} else {
+		sp->state = VALID;
+	}
+	if (wp->sp == NULL && wp->ksp != NULL && wp->ksp->state == VALID) {
+		dm_bde_contribute(wp, wp->bp, wp->length, wp->error);
+		dm_bde_release_keysector(wp);
+		dm_bde_delete_work(wp);
+	}
+	up(&sc->worklist_mutex);
+	return;
+
+}
+
+/*
+ * A write operation has finished.  
+ *
+ * Contrary to FreeBSD, linux can not sleep in the end_io function.
+ * To remedy that, we create a piece of work which we submit to the
+ * generic kernel event thread and let that do the work.
+ * 
+ */
+
+static int
+dm_bde_write_done(struct bio *bp, unsigned int bytes_done, int error)
+{
+	struct dm_bde_sector *sp = (struct dm_bde_sector *) bp->bi_private;
+
+	sp->bytes_done = bytes_done;
+	sp->error = error;
+
+	bio_put(bp);
+
+	INIT_WORK(&sp->wsp, dm_bde_write_done_work, sp);
+	schedule_work(&sp->wsp);
+	
+	return error;
+}
+
+/*
+ * Send a write request for the given sector down the pipeline.
+ */
+
+static int
+dm_bde_start_write(struct dm_bde_sector *sp)
+{
+	struct bio *bp;
+	struct dm_bde_softc *sc;
+
+	sc = sp->softc;
+	KASSERT(sc != NULL, ("NULL sc in dm_bde_start_write"));
+	KASSERT(sp->owner != NULL, ("NULL sp->owner in dm_bde_start_write"));
+
+	bp = bio_alloc(GFP_KERNEL, sp->bi_vcnt);
+	if (bp == NULL)
+		return -ENOMEM;
+
+        bp->bi_idx = 0;
+	bp->bi_vcnt = sp->bi_vcnt;
+
+	bp->bi_private = sp;
+	bp->bi_size = sp->size;
+	bp->bi_bdev = sc->dev->bdev;
+	bp->bi_sector = (sector_t) sp->offset /512; //FIXME
+
+	memcpy(bp->bi_io_vec, sp->bi_io_vec,
+	       sizeof(struct bio_vec) * bp->bi_vcnt);
+
+	bp->bi_end_io = dm_bde_write_done;
+	sp->state = IO;
+
+	submit_bio(WRITE, bp);
+	return(0);
+}
+
+/*
+ * A read operation has finished.  Mark the sector no longer iobusy and
+ * wake up the worker thread and let it do its thing.
+ */
+
+
+
+static int
+dm_bde_read_done(struct bio *bio, unsigned int done, int error)
+{
+	struct dm_bde_sector *sp = (struct dm_bde_sector *) bio->bi_private;
+	struct dm_bde_softc *sc = sp->softc;
+
+	if (bio->bi_size)
+		return 1;
+
+	sp->error = error;
+	if (sp->error == 0)
+		sp->state = VALID;
+	else
+		sp->state = JUNK;
+
+	sc->work_todo=1;
+	wake_up_interruptible(&sc->waitq);
+	return error;
+}
+
+/*
+ * Send a read request for the given keysector down the pipeline.
+ */
+
+int
+dm_bde_start_read(struct dm_bde_work *wp, struct dm_bde_sector *sp)
+{
+	struct bio *bp;
+	struct dm_bde_softc *sc	= wp->softc;
+
+	BUG_ON(sc == NULL);
+	bp = bio_alloc(GFP_KERNEL, sp->bi_vcnt);
+
+	if (bp == NULL)
+		return -ENOMEM;
+
+
+        bp->bi_idx = 0;
+	bp->bi_vcnt = sp->bi_vcnt;
+
+	bp->bi_size = sp->size;
+	bp->bi_bdev = sc->dev->bdev;
+	bp->bi_sector = (sector_t) sp->offset /512; //FIXME
+
+	memcpy(bp->bi_io_vec, sp->bi_io_vec,
+	       sizeof(struct bio_vec) * bp->bi_vcnt);
+
+	bp->bi_private = sp;
+	bp->bi_end_io = dm_bde_read_done;
+	sp->state = IO;
+
+	submit_bio(READ, bp);
+	return(0);
+}
+
+
+extern struct workqueue_struct *_kdmbded_workqueue;
+
+
+/*
+ * The worker thread.
+ *
+ * The up/down path of GEOM is not allowed to sleep or do any major work
+ * so we use this thread to do the actual crypto operations and to push
+ * the state engine onwards.
+ *
+ * XXX: if we switch to the src/sys/opencrypt hardware assisted encryption
+ * XXX: using a thread here is probably not needed.
+ */
+
+
+
+static void kdmbded_do_work(void *data)
+{
+	struct dm_bde_softc *sc = (struct dm_bde_softc *) data;
+	struct list_head *p;
+	struct dm_bde_work *wp;
+	
+	long timeout;
+	unsigned long jiffies1;
+	int error, i;
+	
+	down_interruptible(&sc->worklist_mutex);
+	for (;;) {
+		sc->busy = 0;
+		if (sc->dead)
+			break;
+
+		sc->worklistscans++;
+		list_for_each(p, &sc->worklist) {
+			sc->fetched_wp++;
+
+			wp = list_entry(p, struct dm_bde_work, list);
+			
+			KASSERT(wp != NULL, ("NULL wp"));	
+			KASSERT(wp->softc != NULL, ("NULL wp->softc"));
+
+			if (wp->state != WAIT) {
+				sc->wasted_wait++;
+				continue;		/* Not interesting here */
+			}
+
+			KASSERT(wp->bp != NULL, ("NULL wp->bp"));
+    			KASSERT(wp->sp != NULL, ("NULL wp->sp"));
+
+			if (wp->ksp != NULL) {
+				if (wp->ksp->owner != wp) {
+					sc->wasted_notowner++;
+					continue;
+				}
+				if (wp->ksp->state == IO) {
+					sc->wasted_io++;
+
+					continue;
+				}
+
+				KASSERT(wp->ksp->state == VALID,
+					("Illegal sector state (JUNK ?)"));
+			}
+
+
+			if (bio_data_dir(wp->bp) == READ &&
+			    wp->sp->state == IO) {
+			  sc->wasted_io++;
+			  
+				continue;
+
+			}
+
+
+			if (wp->ksp != NULL && wp->ksp->error != 0) {
+				dm_bde_contribute(wp, wp->bp, wp->length,
+				    wp->ksp->error);
+				dm_bde_delete_sector(sc, wp->sp);
+				dm_bde_release_keysector(wp);
+				dm_bde_delete_work(wp);
+				sc->busy++;
+				break;
+			} 
+
+			switch(bio_data_dir(wp->bp)) {
+			case READ:
+				if (wp->ksp == NULL) {
+					KASSERT(wp->error != 0,
+					    ("BIO_READ, no ksp and no error"));
+					dm_bde_contribute(wp, wp->bp, wp->length,
+						    wp->error);
+				} else {
+				  sc->decrypts++;
+					  if (wp->sp->error == 0) {
+						up(&sc->worklist_mutex);
+						dm_bde_crypt_read(wp);
+						down_interruptible(&sc->worklist_mutex);
+					}
+					dm_bde_contribute(wp, wp->bp, wp->length,
+						    wp->sp->error);
+
+
+				}
+
+				dm_bde_delete_sector(sc, wp->sp);
+				if (wp->ksp != NULL)
+					dm_bde_release_keysector(wp);
+
+				dm_bde_delete_work(wp);
+
+				break;
+			case WRITE:
+				KASSERT(wp->sp->owner == wp, ("Write not owner sp"));
+				KASSERT(wp->ksp->owner == wp, ("Write not owner ksp"));
+
+				wp->sp->size = wp->length;
+				wp->sp->bi_vcnt = wp->bi_vcnt;
+
+
+				for(i = 0 ; i < wp->sp->bi_vcnt ; i++) {
+					wp->sp->bi_io_vec[i].bv_page = alloc_page(GFP_KERNEL);
+					if(!wp->sp->bi_io_vec[i].bv_page) {
+						BUG();
+						while(1);
+					}
+					wp->sp->bi_io_vec[i].bv_len = wp->bi_io_vec[i].bv_len;
+					wp->sp->bi_io_vec[i].bv_offset = wp->bi_io_vec[i].bv_offset;
+				}
+				
+		
+
+				wp->state = FINISH;
+
+				up(&sc->worklist_mutex);
+
+				jiffies1 = jiffies;
+				dm_bde_crypt_write(wp);
+				sc->time_spent_encrypting += (jiffies - jiffies1);
+				sc->encrypt_bytes += wp->length;
+
+				down_interruptible(&sc->worklist_mutex);
+				error = dm_bde_start_write(wp->sp);
+				if (error) {
+					dm_bde_contribute(wp, wp->bp, wp->length, error);
+					dm_bde_release_keysector(wp);
+					dm_bde_delete_sector(sc, wp->sp);
+					dm_bde_delete_work(wp);
+					break;
+				}
+				error = dm_bde_start_write(wp->ksp);
+				if (wp->error == 0)
+					wp->error = error;
+				break;
+			}
+			sc->busy++;
+			break;
+		}
+
+		if (!sc->busy) {
+			/*
+			 * We don't look for our death-warrant until we are
+			 * idle.  Shouldn't make a difference in practice.
+			 */
+			
+
+			if (sc->dead)
+				break;
+
+			sc->work_todo = 0;
+			up(&sc->worklist_mutex);
+			timeout = wait_event_interruptible_timeout(sc->waitq, sc->work_todo != 0, DM_BDE_SLEEP_LENGTH); 
+			down_interruptible(&sc->worklist_mutex);
+
+			sc->sleep_accumulated += DM_BDE_SLEEP_LENGTH - timeout;
+
+			if (!timeout) {
+				/*
+				 * Loose our skey cache in an orderly fashion.
+				 * The exact rate can be tuned to be less
+				 * aggressive if this is desirable.  10% per
+				 * second means that the cache is gone in a
+				 * few minutes.
+				 */
+				dm_bde_purge_sector(sc, 10);
+			
+			}
+		}
+
+
+
+	}
+	ddprintk(BDE "dm_bde_worker die\n");
+	dm_bde_purge_sector(sc, 1);
+	KASSERT(sc->nwork == 0, ("Dead but %d work remaining", sc->nwork));
+	KASSERT(sc->ncache == 0, ("Dead but %d cache remaining", sc->ncache));
+	KASSERT(sc->nsect == 0, ("Dead but %d sect remaining", sc->nsect));
+	up(&sc->worklist_mutex);
+	sc->dead = 2;
+}
+
+void kdmbded_queue_work(struct dm_bde_softc *sc)
+{
+	INIT_WORK(&sc->work, kdmbded_do_work, sc);
+	queue_work(_kdmbded_workqueue, &sc->work);
+}
+
+
+int dm_bde_bvec(struct bio *bio, struct dm_bde_work *wp, int length, int *bv_idx, int *bv_offset)
+{
+	int allocated = 0;
+
+	int nr_bvecs = 1;
+	int wp_bv_idx = 0;
+	struct bio_vec *wp_bvec;
+	struct bio_vec *bvec = bio_iovec_idx(bio, *bv_idx);
+
+	while(allocated < length && *bv_idx < bio->bi_vcnt) {
+		if(bvec->bv_offset + bvec->bv_len - *bv_offset < length - allocated) {
+			/* This bvec cannot satisfy our request for space alone */
+			if(wp) {
+				/* If the wp is allocated, fill in info about bvecs, 
+				 * normally happends on the second run of this function 
+				 */
+
+				wp_bvec = bio_iovec_idx(wp, wp_bv_idx);
+				wp_bvec->bv_page = bvec->bv_page;
+				wp_bvec->bv_offset = *bv_offset;
+				wp_bvec->bv_len = bvec->bv_len - *bv_offset;
+				wp_bv_idx++;
+			}
+
+
+			/* How much space can we allocate from this bvec */
+			allocated += bvec->bv_len - *bv_offset;
+
+			/* Point to next bvec */
+			(*bv_idx)++;
+			bvec = bio_iovec_idx(bio, *bv_idx);
+			*bv_offset = bvec->bv_offset;
+
+			/* Increase count of number of bvecs required */
+			nr_bvecs++;
+		} else {
+			/* This bvec can satisfy our request for remaining space */
+			if(wp) {
+				
+				/* If the wp is allocated, fill in info about bvecs, 
+				 * normally happends on the second run of this function 
+				 */
+
+				wp_bvec = bio_iovec_idx(wp, wp_bv_idx);
+				wp_bvec->bv_page = bvec->bv_page;
+				wp_bvec->bv_offset = *bv_offset;
+				wp_bvec->bv_len = length - allocated;
+				wp_bv_idx++;
+			}
+
+			*bv_offset += length - allocated;
+			allocated = length;
+		}
+	}
+	return nr_bvecs;
+}
+
+
+
+/*
+ * dm_bde_start1 has chopped the incoming request up so all the requests
+ * we see here are inside a single zone.  Map the data and key locations
+
+ * grab the buffers we need and fire off the first volley of read requests.
+ */
+
+static void
+dm_bde_start2(struct dm_bde_work *wp)
+{
+
+	struct dm_bde_softc *sc = wp->softc;
+	
+	if (bio_data_dir(wp->bp) == READ) {
+
+		while(!(wp->sp = dm_bde_new_sector(wp, 0)))
+			blk_congestion_wait(bio_data_dir(wp->bp), HZ/100);
+
+		wp->sp->size = wp->length;
+		wp->sp->bi_vcnt = wp->bi_vcnt;
+		wp->sp->bi_io_vec = wp->bi_io_vec;
+
+		while(dm_bde_start_read(wp, wp->sp))
+			blk_congestion_wait(bio_data_dir(wp->bp), HZ/100);
+
+		sc->sector_reads++;
+
+		do {
+			dm_bde_read_keysector(sc, wp);
+			if(wp->ksp == NULL)
+				blk_congestion_wait(bio_data_dir(wp->bp), HZ/100);
+		} while (wp->ksp ==NULL);
+
+
+	} else if (bio_data_dir(wp->bp) == WRITE) {
+		while(!(wp->sp = dm_bde_new_sector(wp, 0))) {
+			sc->no_new_sector++;
+			sc->work_todo=1;
+			wake_up_interruptible(&sc->waitq);
+			blk_congestion_wait(WRITE, HZ / 1000);
+		}
+
+		/* Fill in memory to hold write */
+
+		wp->sp->bi_io_vec=kmalloc(sizeof(struct bio_vec)*wp->bi_vcnt, GFP_KERNEL);
+		if(!wp->sp->bi_io_vec) {
+			dm_bde_contribute(wp, wp->bp, wp->length, ENOMEM);
+			dm_bde_delete_sector(sc, wp->sp);
+			dm_bde_delete_work(wp);
+			return;
+		}
+		
+		do {
+			dm_bde_read_keysector(sc, wp);
+			if(wp->ksp == NULL) 
+				blk_congestion_wait(READ, HZ / 1000);
+			
+		} while (wp->ksp ==NULL);
+
+
+	}
+
+	wp->state = WAIT;
+	sc->work_todo=1;
+	wake_up_interruptible(&sc->waitq);
+}
+
+
+/*
+ * Create a sequence of work structures, and have dm_bde_map_sector() determine
+ * how long they each can be.  Feed them to dm_bde_start2().
+ */
+
+void
+dm_bde_start1(struct dm_target *ti, struct bio *bp, struct dm_bde_io *io)
+{
+	struct dm_bde_softc *sc = (struct dm_bde_softc *) ti->private; 
+	struct dm_bde_work *wp;
+	
+	unsigned int done;
+
+	int bv_idx_backup;
+	int bv_offset_backup;
+
+	int bv_idx=bp->bi_idx;
+
+	struct bio_vec *bvec=bio_iovec_idx(bp, bv_idx);
+	int bv_offset=bvec->bv_offset;
+
+	atomic_set(&io->completed,0);
+
+	sc->number_of_map_calls++;
+
+
+	/* Keep count on issued number zones we need to touch */
+
+	for(done = 0; done < bp->bi_size; ) {
+
+		while(!(wp = dm_bde_new_work(sc))) 
+			blk_congestion_wait(bio_data_dir(bp), HZ/100);
+		sc->wp_allocated++;
+
+		wp->bp = bp;
+		wp->target = ti;
+		wp->io = io;
+		wp->offset = bp->bi_sector * 512 + done; //FIXME: 512
+		wp->length = bp->bi_size - done;
+		
+		
+		dm_bde_map_sector(wp);
+
+		bv_idx_backup = bv_idx;
+		bv_offset_backup = bv_offset;
+		
+		/* Find out how many bvecs we need to hold this slice of the request */
+		wp->bi_vcnt = dm_bde_bvec(bp, NULL, wp->length, &bv_idx, &bv_offset);
+		
+		/* Allocate these */
+		wp->bi_io_vec=kmalloc(sizeof(struct bio_vec)*wp->bi_vcnt, GFP_KERNEL);
+		if(!wp->bi_io_vec) 
+			BUG();
+
+		/* Setup the bvecs pointing to the pages of the original request */
+		wp->bi_vcnt = dm_bde_bvec(bp, wp, wp->length, &bv_idx_backup, &bv_offset_backup);
+		
+		done += wp->length;
+		dm_bde_start2(wp);
+	}
+	return;
+}
+
diff -Naur linux-2.6.8/drivers/md/dm-bde/Makefile linux-2.6.8-dmbde/drivers/md/dm-bde/Makefile
--- linux-2.6.8/drivers/md/dm-bde/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.8-dmbde/drivers/md/dm-bde/Makefile	2005-11-20 13:26:13.244015800 +0100
@@ -0,0 +1,9 @@
+#
+# Makefile for the BDE system based on FreeBSD's GBDE
+# 
+
+obj-$(CONFIG_DM_BDE)		+= dm_bde.o
+#obj-$(CONFIG_DM_BDE_PERF) 	+= dm_bde_perf.o
+
+dm_bde-objs                     :=dm_bde_main.o dm_bde_lock.o dm_bde_work.o dm_bde_crypt.o 
+#dm_bde_perf-objs		:=dm_bde_performance.o dm_bde_crypt.o
diff -Naur linux-2.6.8/drivers/md/Kconfig linux-2.6.8-dmbde/drivers/md/Kconfig
--- linux-2.6.8/drivers/md/Kconfig	2004-08-14 07:36:16.000000000 +0200
+++ linux-2.6.8-dmbde/drivers/md/Kconfig	2005-11-20 13:35:37.018309080 +0100
@@ -200,5 +200,21 @@
 	  A target that discards writes, and returns all zeroes for
 	  reads.  Useful in some recovery situations.
 
+config DM_BDE
+        tristate "FreeBSD GBDE like transparent crypto support"
+        depends on BLK_DEV_DM && EXPERIMENTAL && !PREEMPT
+        select CRYPTO
+        ---help---
+          This device-mapper target allows you to create a device that
+          transparently encrypts the data on it using the same algorithm
+          used in  FreeBSD's GBDE system. 
+ 
+          To compile this code as a module, choose M here: the module will
+          be called dm_bde.
+		     
+	  This code is not yet safe on preempatible systems.
+
+          If unsure, say N.
+		
 endmenu
 
diff -Naur linux-2.6.8/drivers/md/Makefile linux-2.6.8-dmbde/drivers/md/Makefile
--- linux-2.6.8/drivers/md/Makefile	2004-08-14 07:37:14.000000000 +0200
+++ linux-2.6.8-dmbde/drivers/md/Makefile	2005-11-20 13:29:04.709949016 +0100
@@ -26,6 +26,7 @@
 obj-$(CONFIG_BLK_DEV_MD)	+= md.o
 obj-$(CONFIG_BLK_DEV_DM)	+= dm-mod.o
 obj-$(CONFIG_DM_CRYPT)		+= dm-crypt.o
+obj-$(CONFIG_DM_BDE)		+= dm-bde/
 obj-$(CONFIG_DM_SNAPSHOT)	+= dm-snapshot.o
 obj-$(CONFIG_DM_MIRROR)		+= dm-mirror.o
 obj-$(CONFIG_DM_ZERO)		+= dm-zero.o
